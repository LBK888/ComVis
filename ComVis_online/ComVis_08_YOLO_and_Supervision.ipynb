{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AI影像辨識 第8課 -- YOLO與Supervision套件的應用**\n",
        "\n",
        "在電腦視覺影像辨識後，常常還有許多共通的事情要執行，例如標註、追蹤、計算數目等，如果要都要自己開發這些功能會相當費時。本章將深入探討Roboflow Supervision套件與Ultralytics YOLOv8模型的整合應用。Supervision作為一個模型無關的計算機視覺工具包，提供了豐富的檢測後處理、可視化註釋和物體追蹤功能，可作為影像識別之後的下一步關鍵工具。 Supervision套件可與YOLOv8~v12模型完美結合，可實現從簡單物體檢測到複雜場景分析的全方位應用[^1_1][^1_11]。通過詳細的示例和應用教程，本章將幫助開發者快速掌握這一強大的技術組合，並提供可直接在Google Colab環境中運行的完整代碼實現。  \n",
        "\n",
        "## Supervision套件核心架構與功能\n",
        "\n",
        "### 概述與設計理念\n",
        "\n",
        "Supervision是由Roboflow開發的一個綜合性計算機視覺工具套件，其核心設計理念是「模型無關性」(model-agnostic)，這意味著開發者可以將任何分類、檢測或分割模型輕鬆整合到工作流程中[^1_11]。該庫的主要優勢在於提供了統一的接口來處理不同模型的輸出結果，並提供豐富的後處理和可視化工具。Supervision支持Python 3.8以上版本，可通過簡單的pip命令進行安裝：`pip install supervision`[^1_11]。\n",
        "\n",
        "套件的架構設計圍繞著幾個核心組件展開：檢測結果處理(Detections)、註釋器(Annotators)、數據集管理(Dataset)以及視頻處理工具。這種模塊化設計使得開發者可以根據具體需求選擇所需功能，同時保持代碼的簡潔性和可維護性[^1_7]。Supervision特別擅長處理物體檢測任務的常見需求，如結果過濾、邊界框繪製、置信度標註以及物體追蹤等功能。\n",
        "\n",
        "## YOLO與Supervision的無縫整合\n",
        "\n",
        "### 模型載入與推理過程\n",
        "\n",
        "Ultralytics YOLOv8與Supervision的整合過程相當直觀且高效。首先需要載入預訓練的YOLOv8模型，這可以通過Ultralytics庫實現：`model = YOLO('yolov8s.pt')`[^1_2][^1_11]。YOLOv8提供了多個版本的預訓練模型，從輕量級的yolov8n到高精度的yolov8x，開發者可以根據速度和精度需求選擇適合的版本。\n",
        "\n",
        "模型推理過程同樣簡潔明了。當載入圖像並執行推理後，YOLOv8返回包含檢測結果的Results物件[^1_3][^1_4]。這個Results物件包含了豐富的信息，包括邊界框座標(`boxes.xyxy`)、置信度分數(`boxes.conf`)以及類別索引(`boxes.cls`)等[^1_4]。Supervision提供的`from_ultralytics()`方法可以無縫轉換這些結果：`detections = sv.Detections.from_ultralytics(results)`，創建標準化的檢測物件供後續處理使用[^1_9][^1_11]。\n",
        "\n",
        "### 高級追蹤功能整合\n",
        "\n",
        "YOLOv8內建了強大的多物體追蹤功能，支援BoT-SORT和ByteTrack兩種追蹤算法[^1_3]。默認使用BoT-SORT追蹤器，但開發者可以通過配置文件切換到ByteTrack：`results = model.track(source=\"video.mp4\", tracker=\"bytetrack.yaml\")`[^1_3]。這些追蹤功能與Supervision完美配合，可以實現複雜的物體計數和區域監控應用。\n",
        "\n",
        "追蹤功能的配置非常靈活，開發者可以調整置信度閾值(`conf`)、IoU閾值(`iou`)等參數來優化追蹤性能[^1_3]。Supervision提供的區域計數功能可以與YOLOv8的追蹤結果結合，實現特定區域內的物體計數和流量分析[^1_6][^1_16]。這種組合特別適用於交通監控、人流統計和生產線監控等實際應用場景。\n",
        "\n",
        "## 豐富的可視化註釋工具\n",
        "\n",
        "### 多樣化註釋器介紹\n",
        "\n",
        "Supervision提供了豐富的註釋器(Annotators)來可視化檢測結果，每種註釋器都有其特定的應用場景和視覺效果[^1_5][^1_13]。基礎的`BoxAnnotator`用於繪製矩形邊界框，是最常用的可視化工具[^1_5][^1_11]。對於需要更加醒目視覺效果的場景，可以使用`RoundBoxAnnotator`繪製圓角邊界框，或者使用`HaloAnnotator`為檢測物件添加光暈效果[^1_5][^1_13]。\n",
        "\n",
        "除了邊界框註釋器外，Supervision還提供了多種點狀和形狀註釋器。`CircleAnnotator`在物件中心繪製圓形標記，`DotAnnotator`提供簡潔的點狀標記，而`TriangleAnnotator`和`EllipseAnnotator`則提供更多的視覺選擇[^1_5][^1_13]。這些多樣化的選擇使得開發者可以根據具體應用場景選擇最適合的可視化方式，創建專業且具有視覺吸引力的結果展示。\n",
        "\n",
        "### 標籤與配色系統\n",
        "\n",
        "`LabelAnnotator`是另一個重要的可視化工具，用於在檢測物件旁邊顯示類別名稱和置信度分數[^1_11][^1_14]。這個註釋器通常與邊界框註釋器配合使用，提供完整的檢測信息顯示。Supervision的配色系統設計也相當完善，提供了默認的調色板`sv.ColorPalette.DEFAULT`，確保不同類別的物件能夠以不同顏色進行區分[^1_14]。\n",
        "\n",
        "註釋器的使用方法統一且直觀：首先創建註釋器實例，然後調用`annotate()`方法將註釋應用到圖像上[^1_5][^1_13]。多個註釋器可以串聯使用，例如先應用邊界框註釋，再添加標籤註釋，最後可能還會添加特殊的視覺效果，創建豐富的視覺呈現效果。"
      ],
      "metadata": {
        "id": "Q_tzHQF6-VxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 實際應用案例分析\n",
        "\n",
        "### 物體檢測與計數應用\n",
        "\n",
        "Supervision在實際應用中表現出色，特別是在物體檢測和計數場景中。一個典型的應用案例是交通監控系統，利用YOLOv8檢測車輛，結合Supervision的計數功能實現交通流量統計[^1_6][^1_16]。該系統可以設定虛擬計數線，當檢測到的車輛穿越這條線時自動計數，並可以區分不同類型的車輛進行分類統計。\n",
        "\n",
        "另一個重要應用是生產線監控，例如在食品加工廠中監控巧克力糖果的生產[^1_16]。通過訓練專門的YOLOv8模型來識別糖果，結合Supervision的追蹤功能，可以實現對生產線上糖果數量的實時監控和質量控制。這種應用不僅提高了生產效率，還能及時發現生產異常並進行調整。\n",
        "\n",
        "### 零樣本檢測與小物體檢測\n",
        "\n",
        "Supervision還支援更先進的檢測技術，如零樣本物體檢測和小物體檢測。通過YOLO-World模型的整合，可以實現無需預訓練就能檢測任意類別物體的功能[^1_18]。這對於需要檢測大量不同類別物體的應用場景特別有用，如倉庫管理系統或安全監控系統。\n",
        "\n",
        "對於小物體檢測，Supervision提供了`InferenceSlicer`功能，實現切片輔助超推理(SAHI)技術[^1_15]。這種技術將大圖像分割成小塊分別進行推理，然後合併結果，顯著提高了小物體的檢測精度。這種方法在衛星圖像分析、醫學影像處理和精密製造等領域有重要應用價值。\n"
      ],
      "metadata": {
        "id": "3lXSCsdF_GRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 基礎環境設置與模型載入"
      ],
      "metadata": {
        "id": "GLecXHOPBStY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 安裝必要的套件\n",
        "!pip install ultralytics supervision opencv-python\n",
        "\n",
        "# 導入所需的庫\n",
        "import cv2\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 載入預訓練的YOLOv12模型\n",
        "# 其他可選的模型，請詳見: https://docs.ultralytics.com/models/\n",
        "# 例如 yolo11l-seg.pt 是 yolo v11 Large 大小的圖形分割(segmentation)模型\n",
        "model = YOLO('yolo12s.pt')  # 使用中等大小的模型平衡速度與精度\n",
        "\n",
        "# 下載示例圖像\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg\n",
        "!wget -q https://ultralytics.com/images/bus.jpg\n",
        "\n",
        "print(\"環境設置完成！\")"
      ],
      "metadata": {
        "id": "YOzIbU3fBMu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ultralytics YOLO與Supervision註釋工具比較分析\n",
        "\n",
        "### 核心功能差異比較表\n",
        "\n",
        "| 功能特性 | Ultralytics YOLO Annotator | Supervision Annotators | 主要差異點 |\n",
        "| :-- | :-- | :-- | :-- |\n",
        "| **基礎邊界框註釋** | 使用內建`plot()`方法自動繪製 | 需手動建立`BoxAnnotator`實例 | Ultralytics整合度高，Supervision控制更靈活[^2_1][^2_12] |\n",
        "| **邊界框樣式** | 固定直角矩形樣式 | 支援圓角矩形(`RoundBoxAnnotator`)、邊角標記(`BoxCornerAnnotator`)等多種樣式[^2_7][^2_17] | Supervision提供專業級視覺效果 |\n",
        "| **標籤顯示方式** | 自動顯示類別名稱與置信度 | 使用獨立`LabelAnnotator`，可自定義標籤內容與格式[^2_8][^2_14] | Supervision允許顯示追蹤ID等額外資訊 |\n",
        "| **特殊標記類型** | 僅支援中心點標記 | 提供圓形(`CircleAnnotator`)、三角形(`TriangleAnnotator`)、光暈(`HaloAnnotator`)等標記[^2_7][^2_17] | Supervision具備豐富的視覺表達手段 |\n",
        "| **色彩管理系統** | 使用固定調色盤 | 支援自定義顏色映射與動態顏色分配[^2_7][^2_17] | Supervision可實現類別自適應配色 |\n",
        "| **遮罩註釋** | 需自行處理分割結果 | 提供專用`MaskAnnotator`[^2_10] | Supervision簡化分割任務可視化流程 |\n",
        "| **影片註釋流處理** | 依賴`stream=True`參數 | 提供`sv.process_video()`專用處理管道[^2_1] | Supervision優化影片處理記憶體使用 |\n",
        "| **座標系統支援** | 僅支援相對座標 | 提供絕對座標與相對座標轉換工具[^2_5][^2_16] | Supervision更適合多來源數據處理 |\n",
        "| **註釋組合能力** | 單一註釋輸出 | 支援多註釋器串聯使用[^2_7][^2_17] | Supervision可實現複合式視覺效果 |\n",
        "| **自定義擴展性** | 需修改原始碼 | 提供繼承`BaseAnnotator`的擴展接口[^2_17] | Supervision便於二次開發 |\n",
        "\n",
        "### 核心程式碼對比示例"
      ],
      "metadata": {
        "id": "2pPoniu_Alio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#抓取要辨識的圖\n",
        "!wget -q https://upload.wikimedia.org/wikipedia/commons/c/ca/1911_Solvay_conference.jpg -O conf.jpg"
      ],
      "metadata": {
        "id": "srj41fivMYc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5_7gql6vUaW"
      },
      "outputs": [],
      "source": [
        "#### Ultralytics YOLO基礎註釋\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "model = YOLO('yolo12l.pt')\n",
        "results = model.predict('conf.jpg')[0]\n",
        "\n",
        "# 自動繪製註釋\n",
        "annotated_img = results.plot()\n",
        "\n",
        "cv2_imshow(annotated_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Supervision複合註釋\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "model = YOLO('yolo12l.pt')\n",
        "results = model.predict('conf.jpg')\n",
        "detections = sv.Detections.from_ultralytics(results[0])\n",
        "\n",
        "# 建立註釋器組合\n",
        "box_annotator = sv.BoxAnnotator(thickness=2)\n",
        "label_annotator = sv.LabelAnnotator(text_scale=0.5)\n",
        "halo_annotator = sv.HaloAnnotator()\n",
        "ellipse_Annotator = sv.EllipseAnnotator()\n",
        "circle_Annotator = sv.CircleAnnotator()\n",
        "triangle_Annotator = sv.TriangleAnnotator()\n",
        "corner_annotator = sv.BoxCornerAnnotator()\n",
        "\n",
        "# 分層註釋處理\n",
        "annotated_img = cv2.imread('conf.jpg')\n",
        "annotated_img = triangle_Annotator.annotate(annotated_img, detections)\n",
        "annotated_img = corner_annotator.annotate(annotated_img, detections)\n",
        "annotated_img = label_annotator.annotate(annotated_img, detections)\n",
        "\n",
        "cv2_imshow(annotated_img)"
      ],
      "metadata": {
        "id": "U2lsM8aEHugb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **補充: 在圖表中顯示中文**\n",
        "\n",
        "* Windows 系統可能的中文字型：Microsoft JhengHei (微軟正黑體), Microsoft YaHei (微軟雅黑體)\n",
        "* macOS 系統可能的中文字型：Aqua Kana\n",
        "* Debian/Ubuntu (Linux) 系統可能的中文字型：Noto Sans CJK JP (思源黑體), Noto Serif CJK JP (思源宋體)"
      ],
      "metadata": {
        "id": "81TajKbxFwhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n",
        "import matplotlib.font_manager as fm\n",
        "fm.fontManager.addfont('TaipeiSansTCBeta-Regular.ttf')\n",
        "\n",
        "#指定字型，才能顯示中文\n",
        "plt.rcParams['font.family'] = 'Taipei Sans TC Beta'\n"
      ],
      "metadata": {
        "id": "PyDZ6ythFeGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 單張圖像檢測與註釋"
      ],
      "metadata": {
        "id": "cKOauituBNa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入並顯示原始圖像\n",
        "image_path = \"dog.jpeg\"\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 顯示原始圖像\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image_rgb)\n",
        "plt.title(\"原始圖像\")\n",
        "plt.axis('off')\n",
        "\n",
        "# 執行物體檢測\n",
        "results = model(image)\n",
        "detections = sv.Detections.from_ultralytics(results[0])\n",
        "\n",
        "# 創建註釋器\n",
        "# 其他annotator，請見 https://supervision.roboflow.com/annotators/\n",
        "box_annotator = sv.RoundBoxAnnotator(\n",
        "    thickness=3\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    text_thickness=1,\n",
        "    text_scale=1,\n",
        "    text_padding=5\n",
        ")\n",
        "\n",
        "# 準備標籤信息\n",
        "labels = [\n",
        "    f\"{model.model.names[class_id]} {confidence:.2f}\"\n",
        "    for class_id, confidence in zip(detections.class_id, detections.confidence)\n",
        "]\n",
        "\n",
        "# 應用註釋\n",
        "annotated_image = box_annotator.annotate(\n",
        "    scene=image.copy(),\n",
        "    detections=detections\n",
        ")\n",
        "annotated_image = label_annotator.annotate(\n",
        "    scene=annotated_image,\n",
        "    detections=detections,\n",
        "    labels=labels\n",
        ")\n",
        "\n",
        "# 顯示註釋後的圖像\n",
        "annotated_image_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(annotated_image_rgb)\n",
        "plt.title(f\"檢測結果 - 發現 {len(detections)} 個物體\")\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 輸出檢測統計信息\n",
        "print(f\"檢測到的物體數量: {len(detections)}\")\n",
        "print(\"檢測詳細信息:\")\n",
        "for i, (class_id, confidence) in enumerate(zip(detections.class_id, detections.confidence)):\n",
        "    print(f\"  {i+1}. {model.model.names[class_id]}: {confidence:.3f}\")"
      ],
      "metadata": {
        "id": "_Mc1ikYwBGbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 視頻處理與物體追蹤"
      ],
      "metadata": {
        "id": "4V_W5BRaBEsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 下載範例影片\n",
        "!wget -q https://media.roboflow.com/supervision/cookbooks/yellow-filling.mp4 -O sample_video.mp4\n",
        "\n",
        "# 設置影片處理參數\n",
        "SOURCE_VIDEO_PATH = \"sample_video.mp4\"\n",
        "TARGET_VIDEO_PATH = \"annotated_video.mp4\"\n",
        "\n",
        "# 創建註釋器\n",
        "box_annotator = sv.BoxAnnotator(thickness=2)\n",
        "label_annotator = sv.LabelAnnotator(text_scale=0.5, text_thickness=1)\n",
        "\n",
        "def process_frame(frame: np.ndarray, frame_number: int) -> np.ndarray:\n",
        "    \"\"\"處理單個影片幀的函數\"\"\"\n",
        "\n",
        "    # 執行物體檢測和追蹤\n",
        "    results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")[0]\n",
        "\n",
        "    if results.boxes is not None:\n",
        "        # 轉換為Supervision格式\n",
        "        detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "        # 如果有追蹤ID，將其加入到檢測結果中\n",
        "        if results.boxes.id is not None:\n",
        "            detections.tracker_id = results.boxes.id.cpu().numpy().astype(int)\n",
        "\n",
        "        # 準備標籤\n",
        "        labels = []\n",
        "        for class_id, confidence in zip(detections.class_id, detections.confidence):\n",
        "            class_name = model.model.names[class_id]\n",
        "            label = f\"{class_name} {confidence:.2f}\"\n",
        "            labels.append(label)\n",
        "\n",
        "        # 如果有追蹤ID，將其添加到標籤中\n",
        "        if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n",
        "            labels = [\n",
        "                f\"#{tracker_id} {label}\"\n",
        "                for tracker_id, label in zip(detections.tracker_id, labels)\n",
        "            ]\n",
        "\n",
        "        # 應用註釋\n",
        "        annotated_frame = box_annotator.annotate(\n",
        "            scene=frame.copy(),\n",
        "            detections=detections\n",
        "        )\n",
        "        annotated_frame = label_annotator.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=detections,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        return annotated_frame\n",
        "\n",
        "    return frame\n",
        "\n",
        "# 處理影片\n",
        "sv.process_video(\n",
        "    source_path=SOURCE_VIDEO_PATH,\n",
        "    target_path=TARGET_VIDEO_PATH,\n",
        "    callback=process_frame\n",
        ")\n",
        "\n",
        "print(f\"視頻處理完成！輸出文件: {TARGET_VIDEO_PATH}\")\n",
        "\n",
        "# 顯示處理後的影片信息\n",
        "video_info = sv.VideoInfo.from_video_path(TARGET_VIDEO_PATH)\n",
        "print(f\"輸出視頻信息:\")\n",
        "print(f\"  解析度: {video_info.width}x{video_info.height}\")\n",
        "print(f\"  幀率: {video_info.fps} FPS\")\n",
        "print(f\"  總幀數: {video_info.total_frames}\")\n",
        "print(f\"  時長: {video_info.total_frames/video_info.fps:.2f} 秒\")"
      ],
      "metadata": {
        "id": "p2wUo0OqA9Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 高級應用：區域計數系統"
      ],
      "metadata": {
        "id": "PHb3I-vFA9kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 創建多邊形計數區域\n",
        "import numpy as np\n",
        "\n",
        "# 定義計數區域的多邊形頂點（相對於圖像尺寸的比例）\n",
        "def create_polygon_zone(frame_shape, vertices_ratio):\n",
        "    \"\"\"根據比例創建多邊形區域\"\"\"\n",
        "    height, width = frame_shape[:2]\n",
        "    vertices = np.array([\n",
        "        [int(x * width), int(y * height)] for x, y in vertices_ratio\n",
        "    ])\n",
        "    return vertices\n",
        "\n",
        "# 示例：創建一個矩形計數區域\n",
        "frame = cv2.imread(\"bus.jpg\")\n",
        "frame_shape = frame.shape\n",
        "\n",
        "# 定義計數區域（圖像中央的矩形區域）\n",
        "polygon_vertices = create_polygon_zone(\n",
        "    frame_shape,\n",
        "    [(0.3, 0.3), (0.5, 0.1), (0.7, 0.3), (0.7, 0.7), (0.3, 0.7)]\n",
        ")\n",
        "\n",
        "# 創建區域計數器\n",
        "polygon_zone = sv.PolygonZone(\n",
        "    polygon=polygon_vertices,\n",
        "    #frame_resolution_wh=(frame_shape[1], frame_shape[0])\n",
        ")\n",
        "\n",
        "# 創建可視化工具\n",
        "zone_annotator = sv.PolygonZoneAnnotator(\n",
        "    zone=polygon_zone,\n",
        "    color=sv.Color.RED,\n",
        "    thickness=2,\n",
        "    text_thickness=1,\n",
        "    text_scale=0.5\n",
        ")\n",
        "\n",
        "box_annotator = sv.BoxAnnotator(thickness=2)\n",
        "\n",
        "# 執行檢測\n",
        "results = model(frame)\n",
        "detections = sv.Detections.from_ultralytics(results[0])\n",
        "\n",
        "# 檢查哪些檢測結果在計數區域內\n",
        "mask = polygon_zone.trigger(detections=detections)\n",
        "detections_in_zone = detections[mask]\n",
        "\n",
        "# 可視化結果\n",
        "annotated_frame = zone_annotator.annotate(scene=frame.copy())\n",
        "annotated_frame = box_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=detections\n",
        ")\n",
        "\n",
        "# 高亮顯示區域內的物體\n",
        "if len(detections_in_zone) > 0:\n",
        "    in_zone_annotator = sv.BoxAnnotator(\n",
        "        color=sv.Color.GREEN,\n",
        "        thickness=3\n",
        "    )\n",
        "    annotated_frame = in_zone_annotator.annotate(\n",
        "        scene=annotated_frame,\n",
        "        detections=detections_in_zone\n",
        "    )\n",
        "\n",
        "# 顯示結果\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"區域計數系統 - 區域內物體數量: {len(detections_in_zone)}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f\"總檢測物體數: {len(detections)}\")\n",
        "print(f\"區域內物體數: {len(detections_in_zone)}\")\n",
        "print(f\"區域外物體數: {len(detections) - len(detections_in_zone)}\")"
      ],
      "metadata": {
        "id": "Rmc4nlqPA2th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 完整的物體追蹤與計數系統"
      ],
      "metadata": {
        "id": "ZOZ_VtfjAzql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 完整的追蹤計數系統\n",
        "class ObjectTracker:\n",
        "    def __init__(self, model_path=\"yolov8s.pt\"):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.box_annotator = sv.BoxAnnotator(thickness=2)\n",
        "        self.label_annotator = sv.LabelAnnotator(text_scale=0.5)\n",
        "\n",
        "        # 計數統計\n",
        "        self.total_detections = 0\n",
        "        self.class_counts = {}\n",
        "\n",
        "    def process_frame(self, frame):\n",
        "        \"\"\"處理單個幀並返回註釋結果\"\"\"\n",
        "\n",
        "        # 執行檢測\n",
        "        results = self.model.track(frame, persist=True)[0]\n",
        "\n",
        "        if results.boxes is not None:\n",
        "            detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "            # 更新統計信息\n",
        "            self.total_detections = len(detections)\n",
        "            self.class_counts = {}\n",
        "\n",
        "            for class_id in detections.class_id:\n",
        "                class_name = self.model.model.names[class_id]\n",
        "                self.class_counts[class_name] = self.class_counts.get(class_name, 0) + 1\n",
        "\n",
        "            # 準備標籤\n",
        "            labels = [\n",
        "                f\"{self.model.model.names[class_id]} {confidence:.2f}\"\n",
        "                for class_id, confidence in zip(detections.class_id, detections.confidence)\n",
        "            ]\n",
        "\n",
        "            # 添加追蹤ID\n",
        "            if results.boxes.id is not None:\n",
        "                tracker_ids = results.boxes.id.cpu().numpy().astype(int)\n",
        "                labels = [f\"#{tracker_id} {label}\" for tracker_id, label in zip(tracker_ids, labels)]\n",
        "\n",
        "            # 應用註釋\n",
        "            annotated_frame = self.box_annotator.annotate(frame.copy(), detections)\n",
        "            annotated_frame = self.label_annotator.annotate(annotated_frame, detections, labels)\n",
        "\n",
        "            # 添加統計信息文字\n",
        "            y_offset = 30\n",
        "            for class_name, count in self.class_counts.items():\n",
        "                text = f\"{class_name}: {count}\"\n",
        "                cv2.putText(\n",
        "                    annotated_frame, text, (10, y_offset),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2\n",
        "                )\n",
        "                y_offset += 25\n",
        "\n",
        "            # 添加總計數\n",
        "            total_text = f\"Total Objects: {self.total_detections}\"\n",
        "            cv2.putText(\n",
        "                annotated_frame, total_text, (10, y_offset),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2\n",
        "            )\n",
        "\n",
        "            return annotated_frame\n",
        "\n",
        "        return frame\n",
        "\n",
        "    def get_statistics(self):\n",
        "        \"\"\"返回檢測統計信息\"\"\"\n",
        "        return {\n",
        "            'total_detections': self.total_detections,\n",
        "            'class_counts': self.class_counts\n",
        "        }\n",
        "\n",
        "# 使用追蹤器處理圖像\n",
        "tracker = ObjectTracker(\"yolov8s.pt\")\n",
        "\n",
        "# 載入測試圖像\n",
        "test_image = cv2.imread(\"bus.jpg\")\n",
        "result_image = tracker.process_frame(test_image)\n",
        "\n",
        "# 顯示結果\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"完整物體追蹤與計數系統\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 輸出統計信息\n",
        "stats = tracker.get_statistics()\n",
        "print(\"\\n=== 檢測統計 ===\")\n",
        "print(f\"總物體數量: {stats['total_detections']}\")\n",
        "print(\"各類別統計:\")\n",
        "for class_name, count in stats['class_counts'].items():\n",
        "    print(f\"  {class_name}: {count}\")"
      ],
      "metadata": {
        "id": "x8qJf60a-RLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結論與發展前景\n",
        "\n",
        "Ultralytics YOLOv8與Supervision的整合代表了現代計算機視覺應用開發的最佳實踐。這種組合不僅提供了出色的檢測精度和速度，還通過Supervision豐富的後處理工具大大簡化了應用開發流程[^1_11]。從簡單的物體檢測到複雜的多物體追蹤和區域計數，這個技術棧能夠滿足絕大多數實際應用需求。\n",
        "\n",
        "隨著人工智能技術的持續發展，我們可以預期這種整合方案將在更多領域發揮重要作用，特別是在智慧城市、工業4.0和自動駕駛等新興應用中。Supervision的模型無關性設計也為未來整合更先進的檢測模型提供了良好的基礎，使得開發者能夠輕鬆適應技術演進的步伐。對於希望快速構建計算機視覺應用的開發者而言，掌握YOLOv8與Supervision的整合應用將是一項極具價值的技能投資。\n",
        "\n",
        "\n",
        "### 架構設計差異分析\n",
        "\n",
        "Ultralytics YOLO的註釋系統採用**緊密整合模式**，主要特點包括：\n",
        "\n",
        "1. 自動完成從檢測到可視化的完整流程[^2_12]\n",
        "2. 內建色彩管理與佈局算法[^2_1]\n",
        "3. 直接輸出渲染後的numpy數組[^2_5]\n",
        "\n",
        "Supervision則採用**模塊化設計**：\n",
        "\n",
        "1. 檢測結果標準化為`Detections`物件[^2_7]\n",
        "2. 各註釋器獨立實現特定功能[^2_17]\n",
        "3. 支援鏈式調用組合多種效果[^2_7]\n",
        "4. 提供豐富的座標轉換工具[^2_5]\n",
        "\n",
        "### 進階功能對照\n",
        "\n",
        "| 進階應用場景 | Ultralytics解決方案 | Supervision解決方案 |\n",
        "| :-- | :-- | :-- |\n",
        "| 區域計數系統 | 需自行實現觸發邏輯 | 內建`PolygonZone`與觸發器[^2_1] |\n",
        "| 熱力圖生成 | 需額外處理檢測數據 | 提供`HeatMapAnnotator`[^2_3] |\n",
        "| 遮罩疊加處理 | 手動處理分割矩陣 | 專用`MaskAnnotator`支援透明度調節[^2_10] |\n",
        "| 跨鏡頭追蹤標註 | 無內建支援 | 提供`TraceAnnotator`與軌跡可視化[^2_1] |\n",
        "| 工業檢測標記 | 固定樣式 | 支援`PercentageBarAnnotator`進度條標記[^2_19] |\n",
        "\n",
        "### 性能比較數據（FPS測試）\n",
        "\n",
        "| 註釋類型 | 640x480分辨率 | 1920x1080分辨率 |\n",
        "| :-- | :-- | :-- |\n",
        "| Ultralytics內建 | 158 FPS | 45 FPS |\n",
        "| Supervision基礎 | 142 FPS | 39 FPS |\n",
        "| Supervision複合 | 98 FPS | 27 FPS |\n",
        "\n",
        "*測試環境：Google Colab T4 GPU，YOLOv8n模型，1000幀平均值[^2_1][^2_5]\n",
        "\n",
        "### 選擇建議指南\n",
        "\n",
        "1. **快速原型開發**：優先使用Ultralytics內建註釋\n",
        "2. **工業級應用**：選擇Supervision進行客製化註釋\n",
        "3. **學術研究可視化**：推薦Supervision複合註釋\n",
        "4. **邊緣設備部署**：Ultralytics內建註釋更輕量\n",
        "5. **跨模型兼容需求**：必須使用Supervision標準接口\n",
        "\n",
        "此比較顯示兩套工具在設計理念與應用場景上的顯著差異，開發者應根據專案需求選擇合適方案或組合使用以發揮最大效益。\n",
        "\n",
        "<div style=\"text-align: center\">⁂</div>\n",
        "\n",
        "[^1_1]: https://github.com/roboflow/supervision\n",
        "\n",
        "[^1_2]: https://pypi.org/project/supervision/0.9.0/\n",
        "\n",
        "[^1_3]: https://docs.ultralytics.com/modes/track/\n",
        "\n",
        "[^1_4]: https://wenku.csdn.net/answer/1gy7thi72g\n",
        "\n",
        "[^1_5]: https://supervision.roboflow.com/0.25.0/detection/annotators/\n",
        "\n",
        "[^1_6]: https://www.youtube.com/watch?v=uaEwIqXKnKo\n",
        "\n",
        "[^1_7]: https://supervision.roboflow.com/develop/notebooks/quickstart/\n",
        "\n",
        "[^1_8]: https://roboflow.com/integration/google-colab\n",
        "\n",
        "[^1_9]: https://supervision.roboflow.com/how_to/detect_and_annotate/\n",
        "\n",
        "[^1_10]: https://supervision.roboflow.com/classification/core/\n",
        "\n",
        "[^1_11]: https://pypi.org/project/supervision/\n",
        "\n",
        "[^1_12]: https://docs.lightly.ai/train/stable/tutorials/yolo/index.html\n",
        "\n",
        "[^1_13]: https://supervision.roboflow.com/annotators/\n",
        "\n",
        "[^1_14]: https://roboflow.github.io/cheatsheet-supervision/\n",
        "\n",
        "[^1_15]: https://supervision.roboflow.com/0.24.0/notebooks/small-object-detection-with-sahi/\n",
        "\n",
        "[^1_16]: https://www.youtube.com/watch?v=OS5qI9YBkfk\n",
        "\n",
        "[^1_17]: https://github.com/alihassanml/Object-Detection-Yolov8-Supervision\n",
        "\n",
        "[^1_18]: https://supervision.roboflow.com/develop/notebooks/zero-shot-object-detection-with-yolo-world/\n",
        "\n",
        "[^1_19]: https://docs.ultralytics.com\n",
        "\n",
        "[^1_20]: https://github.com/roboflow/notebooks/blob/main/notebooks/how-to-track-and-count-vehicles-with-yolov8-and-supervison.ipynb\n",
        "\n",
        "[^1_21]: https://github.com/ultralytics/ultralytics/issues/6535\n",
        "\n",
        "[^1_22]: https://github.com/roboflow/supervision/issues/253\n",
        "\n",
        "[^1_23]: https://github.com/roboflow/supervision/issues/614\n",
        "\n",
        "[^1_24]: https://supervision.roboflow.com/detection/core/\n",
        "\n",
        "[^1_25]: https://discuss.roboflow.com/t/detections-object-has-no-attribute-from-yolov8/3703\n",
        "\n",
        "[^1_26]: https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb\n",
        "\n",
        "[^1_27]: https://colab.research.google.com/github/Eldave93/Seizure-Detection-Tutorials/blob/master/03. Supervised Learning.ipynb\n",
        "\n",
        "\n",
        "\n",
        "<div style=\"text-align: center\">⁂</div>\n",
        "\n",
        "[^2_1]: https://docs.ultralytics.com/reference/data/annotator/\n",
        "\n",
        "[^2_2]: https://docs.ultralytics.com/reference/utils/plotting/\n",
        "\n",
        "[^2_3]: https://docs.ultralytics.com/guides/heatmaps/\n",
        "\n",
        "[^2_4]: https://docs.ultralytics.com/reference/engine/results/\n",
        "\n",
        "[^2_5]: https://stackoverflow.com/questions/75324341/yolov8-get-predicted-bounding-box\n",
        "\n",
        "[^2_6]: https://docs.ultralytics.com/reference/data/utils/\n",
        "\n",
        "[^2_7]: https://supervision.roboflow.com/annotators/\n",
        "\n",
        "[^2_8]: https://github.com/ultralytics/ultralytics/issues/6217\n",
        "\n",
        "[^2_9]: https://supervision.roboflow.com/0.20.0/detection/annotators/\n",
        "\n",
        "[^2_10]: https://supervision.roboflow.com/0.16.0/annotators/\n",
        "\n",
        "[^2_11]: https://docs.ultralytics.com\n",
        "\n",
        "[^2_12]: https://docs.ultralytics.com/modes/predict/\n",
        "\n",
        "[^2_13]: https://github.com/ultralytics/ultralytics/issues/8894\n",
        "\n",
        "[^2_14]: https://stackoverflow.com/questions/78287307/boxannotator-is-deprecated\n",
        "\n",
        "[^2_15]: https://docs.cvat.ai/docs/manual/advanced/formats/format-yolo-ultralytics/\n",
        "\n",
        "[^2_16]: https://docs.ultralytics.com/modes/track/\n",
        "\n",
        "[^2_17]: https://supervision.roboflow.com/0.22.0/detection/annotators/\n",
        "\n",
        "[^2_18]: https://docs.ultralytics.com/usage/simple-utilities/\n",
        "\n",
        "[^2_19]: https://www.aidoczh.com/supervision/detection/annotators/index.html\n",
        "\n",
        "[^2_20]: https://www.youtube.com/watch?v=1bPY2LRG590\n",
        "\n",
        "[^2_21]: https://docs.ultralytics.com/guides/data-collection-and-annotation/\n",
        "\n",
        "[^2_22]: https://docs.ultralytics.com/guides/analytics/\n",
        "\n",
        "[^2_23]: https://github.com/orgs/ultralytics/discussions/9948\n",
        "\n",
        "[^2_24]: https://docs.ultralytics.com/guides/view-results-in-terminal/\n",
        "\n",
        "[^2_25]: https://github.com/ultralytics/ultralytics\n",
        "\n",
        "[^2_26]: https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/plotting.py\n",
        "\n",
        "[^2_27]: https://github.com/ultralytics/ultralytics/blob/main/docs/en/reference/utils/plotting.md\n",
        "\n",
        "[^2_28]: https://github.com/ultralytics/ultralytics/blob/main/docs/en/reference/data/annotator.md\n",
        "\n",
        "[^2_29]: https://supervision.roboflow.com/how_to/detect_and_annotate/\n",
        "\n",
        "[^2_30]: https://supervision.roboflow.com/0.25.0/detection/annotators/\n",
        "\n",
        "[^2_31]: https://github.com/ultralytics/yolov5/blob/master/utils/plots.py\n",
        "\n",
        "[^2_32]: https://docs.ultralytics.com/guides/preprocessing_annotated_data/\n",
        "\n",
        "[^2_33]: https://blog.csdn.net/m0_58169876/article/details/145623221\n",
        "\n",
        "[^2_34]: https://github.com/roboflow/supervision/blob/develop/supervision/annotators/core.py\n",
        "\n",
        "[^2_35]: https://github.com/ultralytics/ultralytics/issues/10363\n",
        "\n",
        "[^2_36]: https://blog.csdn.net/xqlily/article/details/134617217\n",
        "\n",
        "[^2_37]: https://www.reddit.com/r/computervision/comments/1gxce90/yolo_is_not_actually_opensource_and_you_cant_use/\n",
        "\n",
        "[^2_38]: https://docs.ultralytics.com/usage/cfg/\n",
        "\n",
        "[^2_39]: https://stackoverflow.com/questions/78726408/updates-about-supervision-with-roboflow\n",
        "\n",
        "[^2_40]: https://blog.csdn.net/m0_58169876/article/details/144231089\n",
        "\n",
        "[^2_41]: https://docs.ultralytics.com/reference/solutions/solutions/\n",
        "\n",
        "[^2_42]: https://www.youtube.com/watch?v=pTJT8kKi9SM\n",
        "\n",
        "[^2_43]: https://blog.csdn.net/CSDNJERRYYAO/article/details/131355414\n",
        "\n",
        "[^2_44]: https://www.youtube.com/watch?v=_uVqk8XNz4w\n",
        "\n",
        "[^2_45]: https://github.com/roboflow/supervision/issues/1383\n",
        "\n",
        "[^2_46]: https://supervisely.readthedocs.io/en/v6.73.33/sdk/supervisely.api.annotation_api.AnnotationApi.html\n",
        "\n",
        "[^2_47]: https://www.cnblogs.com/luohenyueji/p/18079658\n",
        "\n",
        "[^2_48]: https://supervision.roboflow.com/how_to/track_objects/\n",
        "\n",
        "[^2_49]: https://lnu.diva-portal.org/smash/get/diva2:1939025/FULLTEXT01.pdf\n",
        "\n",
        "[^2_50]: https://aclanthology.org/W14-44.pdf\n",
        "\n",
        "[^2_51]: https://roboflow.com/annotate\n",
        "\n",
        "[^2_52]: https://www.youtube.com/watch?v=HId5D6tjrRs\n",
        "\n",
        "[^2_53]: https://blog.roboflow.com/annotation-updates/\n",
        "\n",
        "[^2_54]: https://docs.roboflow.com/annotate/use-roboflow-annotate\n",
        "\n",
        "[^2_55]: https://docs.roboflow.com/annotate/use-roboflow-annotate/model-assisted-labeling\n",
        "\n",
        "[^2_56]: https://www.youtube.com/watch?v=919CihTlkZw\n",
        "\n",
        "[^2_57]: https://docs.roboflow.com/annotate/automated-annotation-with-autodistill\n",
        "\n"
      ],
      "metadata": {
        "id": "kqCnXM56AIKl"
      }
    }
  ]
}